# LLM inference with Rust

Inspired by [karpathy/llama2.c][https://github.com/karpathy/llama2.c].

## Usage

```shell
cargo run --bin llm_rs
```

## History

* [v0.0.1][https://github.com/zhihuij/]: Initial version (6.05 token/s)
* [v0.0.2][https://github.com/zhihuij/]: Data Parallelism with Rayon (14.39 token/s)

## License

This project is licensed under the [MIT license][https://github.com/zhihuij/].
